'''Generates annotation data sets for cross-validation of deepNF embeddings.

Saves a .mat file containing arrays of genes and their associated GO terms for
each of the three GO ontologies and for three levels of term counts in each
ontology.

Usage:
    python cross_validation_annotations.py
'''
import os
import itertools
import numpy as np
from scipy import io
import pandas as pd
from goatools.godag_obosm import OboToGoDagSmall
from agape.load import Genes
from agape.gene_ontology import GO
from agape.utils import directory_exists


def parent_terms(go_dag, go_id):
    '''Return parent terms of `go_id` in a `go_dag`.
    '''
    sub_dag = OboToGoDagSmall(goids=[go_id], obodag=go_dag).godag
    all_parents = list(sub_dag.go2obj.keys())
    return all_parents


def propagate_parent_terms(associations, go_dag):
    '''Propagate gene annotations to parent terms.

    # Arguments
        associations: dict, mapping genes to GO terms generated by
            agape.GO.get_associations
    '''
    for gene, go_ids in associations.items():
        for go_id in go_ids.copy():
            try:
                parents = parent_terms(go_dag, go_id)
                for i in parents:
                    associations[gene].add(i)
            except KeyError as err:
                err.args = (f'Obsolete term: {err.args[0]}',)
                pass
    return associations


def get_gene_index():
    '''Return a dictionary mapping genes to array indices.
    '''
    genes = pd.read_csv(os.path.join(os.path.expandvars('$AGAPEDATA'),
                        'deepNF', 'networks', 'yeast_net_genes.csv'),
                        header=None)[0]
    genes = genes.str[5:-2]
    return {k: v for k, v in zip(sorted(genes), range(len(genes)))}


def get_go_id_index(d):
    '''Return a dictionary mapping GO terms to array indices.
    '''
    go_ids = set(itertools.chain(*d.values()))
    return {k: v for k, v in zip(sorted(go_ids), range(len(go_ids)))}


def fill_array_of_associations(M, associations, gene_indexes, go_id_indexes):
    '''Return an array of associations between genes and GO terms.

    Shape = [n_go_terms, n_genes]

    # Arguments
        M: array, np.zeros((n_go_terms, n_genes))
        gene_indexes: dict, mapping genes to array indices
        go_id_indexes: dict, mapping GO terms to array indices

    # Returns
        M: array, filled
    '''
    for gene, go_ids in associations.items():
        try:
            gene_index = gene_indexes[gene]
            for go_id in go_ids:
                go_id_index = go_id_indexes[go_id]
                M[go_id_index, gene_index] = 1
        except KeyError as err:
            # print(err)
            pass
    return M


def get_subarray_by_term_counts(M, vmin, vmax):
    '''Return a subarray containing terms with vmin <= count <= vmax.

    # Arguments
        M: array, associations between genes and GO terms
        vmin: int, minimum term count
        vmax: int, maximum term count

    # Returns
        M: subarray
    '''
    n_terms = M.sum(1)
    M = M[(vmin <= n_terms) & (n_terms <= vmax), :]
    return M


def filter_similar_terms(M, threshold=0.1):
    '''Filter out similar GO terms.

    # Arguments
        M: array, associations between genes and GO terms
        threshold: float, Jaccard similarity threshold

    # Returns
        M: subarray, with similar terms filtered out
    '''
    termsize = M.sum(1)
    indexes = termsize.argsort()
    M = M[indexes]

    intersection = M @ M.T
    union = M.shape[1] - (1 - M) @ (1 - M).T
    jacc = intersection / union

    max_jacc = np.triu(jacc, 1).max(1)
    M = M[max_jacc <= threshold]
    return M


def main():
    '''Run for each ontology and for three levels of term counts.
    '''
    # Load GO DAG
    go = GO("experimental", "curated")
    go.load_go_dag()
    go_dag = go.go_dag

    # Set `vmin` and `vmax` for each level of term counts
    ontology_sizes = [(101, 300), (31, 100), (11, 30)]

    # Names of the three ontologies
    ontologies = ['P', 'F', 'C']

    # Save arrays for each ontology and level
    associations_ontologies_levels = {}

    # Loop over ontologies
    for ontology in ontologies:
        print('Calculating for ontology', ontology)
        # Get dict mapping genes to GO terms
        associations = go.get_associations(ontology)
        # Add parent terms
        associations = propagate_parent_terms(associations, go_dag)
        # Get dicts for mapping to array indexes
        gene_indexes = get_gene_index()
        go_id_indexes = get_go_id_index(associations)

        # Loop over levels of term counts
        for idx, (vmin, vmax) in enumerate(ontology_sizes):
            print('Min/max term counts', vmin, vmax)
            # Get associations between genes and GO terms
            M = np.zeros((max(go_id_indexes.values()) + 1,
                          max(gene_indexes.values()) + 1))
            M = fill_array_of_associations(M, associations, gene_indexes,
                                           go_id_indexes)
            M = get_subarray_by_term_counts(M, vmin, vmax)
            print('Shape before filtering terms by Jaccard similarity', M.shape)
            # Filter terms by Jaccard similarity
            M = filter_similar_terms(M)
            print('Shape after filtering terms by Jaccard similarity', M.shape)
            # Save array
            associations_ontologies_levels[f'{ontology}_{idx + 1}'] = M.T

    # Save `associations_ontologies_levels` to a .mat file
    output_dir = os.path.join(os.path.expandvars('$AGAPEDATA'), 'deepNF',
                              'annotations')
    directory_exists(output_dir)
    output_file = 'yeast_annotations.mat'
    io.savemat(
        os.path.join(output_dir, output_file),
        associations_ontologies_levels,
        do_compression=True)

    print(f'{output_file} saved to {output_dir}')


if __name__ == '__main__':
    print(__doc__)
    main()
